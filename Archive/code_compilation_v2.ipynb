{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPcKkvUyDd86zL0QZvGXJll"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Compiling code\n","\n","1.   Object detection in Video\n","2.   Eye blink detection\n","3.   Face recognition\n","\n"],"metadata":{"id":"-VDLaQ_MWWO8"}},{"cell_type":"markdown","source":["Mounting google drive"],"metadata":{"id":"HNR1jRB3cQhD"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"yK3D_B1EWVPX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717664025075,"user_tz":-330,"elapsed":27144,"user":{"displayName":"atul kashyap","userId":"02181211827561551789"}},"outputId":"abc8269f-0965-4b19-87fb-facd9d357a12"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","path = '/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled'\n","os.chdir(path)"]},{"cell_type":"markdown","source":["Importing the required libraries"],"metadata":{"id":"anWGrmEfcik2"}},{"cell_type":"code","source":["!pip install ultralytics\n","!pip install deepface\n","!pip install \"/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/Dependencies/dlib-19.24.1-cp311-cp311-win_amd64.whl\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"F2dXeviacwOk","executionInfo":{"status":"ok","timestamp":1717664123167,"user_tz":-330,"elapsed":84084,"user":{"displayName":"atul kashyap","userId":"02181211827561551789"}},"outputId":"c9f1b863-0739-4d85-c36b-cf68def0965f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.2.28-py3-none-any.whl (779 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/779.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.7/779.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.6/779.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Collecting ultralytics-thop>=0.2.5 (from ultralytics)\n","  Downloading ultralytics_thop-0.2.7-py3-none-any.whl (25 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.28 ultralytics-thop-0.2.7\n","Collecting deepface\n","  Downloading deepface-0.0.91-py3-none-any.whl (97 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.31.0)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.25.2)\n","Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.0.3)\n","Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (5.1.0)\n","Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.66.4)\n","Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (9.4.0)\n","Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.8.0.76)\n","Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.15.0)\n","Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.15.0)\n","Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.2.5)\n","Collecting mtcnn>=0.1.0 (from deepface)\n","  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting retina-face>=0.0.1 (from deepface)\n","  Downloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n","Collecting fire>=0.4.0 (from deepface)\n","  Downloading fire-0.6.0.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gunicorn>=20.1.0 (from deepface)\n","  Downloading gunicorn-22.0.0-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (1.16.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (2.4.0)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.0.3)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.4)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (8.1.7)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (3.14.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gunicorn>=20.1.0->deepface) (24.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (2024.6.2)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (67.7.2)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (4.12.1)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.64.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.43.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=1.1.2->deepface) (2.1.5)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (0.7.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.5)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (1.7.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (1.3.1)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (3.2.2)\n","Building wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117029 sha256=296b11917e9e7a3e83f67907c753fda3a460576442ec854617683b81b0b996d6\n","  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n","Successfully built fire\n","Installing collected packages: gunicorn, fire, mtcnn, retina-face, deepface\n","Successfully installed deepface-0.0.91 fire-0.6.0 gunicorn-22.0.0 mtcnn-0.1.1 retina-face-0.0.17\n","\u001b[31mERROR: dlib-19.24.1-cp311-cp311-win_amd64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","import cv2\n","from google.colab.patches import cv2_imshow\n","from ultralytics import YOLO\n","\n","import dlib\n","from imutils import face_utils\n","from scipy.spatial import distance as dist\n","\n","from deepface import DeepFace\n","\n","import time\n","\n","# Start timer\n","tic = time.time()\n","\n","# Load the pre-trained model for YOLOv8\n","model = YOLO('yolov8m.pt')\n","\n","# Path to the video\n","video_path = '/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4'\n","\n","# Run the video through the model\n","results = model(source=video_path, show=True, conf=0.4, save=True)\n","\n","# Initialize an empty set to store unique object names\n","detected_objects = set()\n","\n","# Process the results\n","for result in results:\n","    for detection in result.boxes.data:\n","        class_id = int(detection[5])\n","        class_name = model.names[class_id]\n","        detected_objects.add(class_name)\n","\n","# Convert the set to a list to get the final list of detected objects\n","objects_list = list(detected_objects)\n","print(objects_list)\n","print('\\n')\n","\n","# Check for unauthorized objects\n","objects_of_interest = [\"cell phone\"]  # \"laptop\"\n","if any(obj in objects_list for obj in objects_of_interest):\n","    print(\"UNAUTHORISED ACCESS: Phone/Laptop is detected.\")\n","else:\n","    print('Moving to eye-blink detection.\\n')\n","\n","    def eye_aspect_ratio(eye):\n","        A = dist.euclidean(eye[1], eye[5])\n","        B = dist.euclidean(eye[2], eye[4])\n","        C = dist.euclidean(eye[0], eye[3])\n","        ear = (A + B) / (2.0 * C)\n","        return ear\n","\n","    EYE_AR_THRESH = 0.21\n","    EYE_AR_CONSEC_FRAMES = 5\n","\n","    # Initialize counters\n","    COUNTER = 0\n","    TOTAL = 0\n","\n","    # Initialize dlib's face detector and create the facial landmark predictor\n","    detector = dlib.get_frontal_face_detector()\n","    predictor = dlib.shape_predictor('/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/Dependencies/shape_predictor_68_face_landmarks.dat')\n","\n","    (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n","    (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n","\n","    # Open the video file again for eye blink detection\n","    cap = cv2.VideoCapture(video_path)\n","\n","    # Get the width and height of the frames in the video\n","    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","    # Define the codec and create VideoWriter object\n","    output_path = '/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/outputs/output - Ashish.avi'\n","    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'XVID'), 10, (frame_width, frame_height))\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","        rects = detector(gray, 0)\n","\n","        for rect in rects:\n","            shape = predictor(gray, rect)\n","            shape = face_utils.shape_to_np(shape)\n","\n","            leftEye = shape[lStart:lEnd]\n","            rightEye = shape[rStart:rEnd]\n","            leftEAR = eye_aspect_ratio(leftEye)\n","            rightEAR = eye_aspect_ratio(rightEye)\n","\n","            ear = (leftEAR + rightEAR) / 2.0\n","\n","            leftEyeHull = cv2.convexHull(leftEye)\n","            rightEyeHull = cv2.convexHull(rightEye)\n","            cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n","            cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n","\n","            if ear < EYE_AR_THRESH:\n","                COUNTER += 1\n","            else:\n","                if COUNTER >= EYE_AR_CONSEC_FRAMES:\n","                    TOTAL += 1\n","                COUNTER = 0\n","\n","            cv2.putText(frame, \"Blinks: {}\".format(TOTAL), (10, 30),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 0, 255), 2)\n","\n","        # Write the frame to the output video file\n","        out.write(frame)\n","\n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            break\n","\n","    cap.release()\n","    out.release()\n","    cv2.destroyAllWindows()\n","\n","    # Print the final number of blinks\n","    print(f\"Total number of blinks detected: {TOTAL}\")\n","\n","    if not TOTAL:\n","        print('UNAUTHORISED ACCESS: Spoofing detected')\n","    else:\n","        print('Moving to face detection.')\n","\n","        # Initialize variables to store the highest scoring person object and its corresponding frame\n","        highest_score = 0\n","        person_bbox_with_highest_score = None\n","        frame_with_highest_score = None\n","\n","        # Open the video file again for face detection\n","        cap = cv2.VideoCapture(video_path)\n","\n","        # Iterate over the detected frames\n","        for frame_idx, frame_results in enumerate(results):\n","            for detection in frame_results.boxes.data:\n","                x1, y1, x2, y2, conf, cls = detection\n","\n","                # Check if the detected object is a person (assuming class '0' corresponds to 'person')\n","                if int(cls) == 0 and conf > highest_score:\n","                    highest_score = conf\n","                    person_bbox_with_highest_score = (int(x1), int(y1), int(x2), int(y2))\n","\n","                    # Set the video frame to the current frame index\n","                    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n","                    ret, frame_with_highest_score = cap.read()\n","\n","        cap.release()\n","\n","        # If a person object with the highest score is found, crop the corresponding region from the frame\n","        if person_bbox_with_highest_score is not None and frame_with_highest_score is not None:\n","            x1, y1, x2, y2 = person_bbox_with_highest_score\n","            cropped_person = frame_with_highest_score[y1:y2, x1:x2]\n","            # Display or save the cropped person image\n","            print(f'Frame no. {frame_idx}: {highest_score}')\n","            # cv2_imshow(cropped_person)\n","            cv2.waitKey(0)\n","            cv2.destroyAllWindows()\n","\n","\n","            # --------- FACE RECOGNITION ---------\n","\n","            # Path to the database directory\n","            db_path = \"/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/Faces/train/AshishGhule\"\n","\n","            # Perform facial recognition\n","            result = DeepFace.find(cropped_person, db_path, enforce_detection=True)\n","            # result\n","\n","\n","            if min(result[0]['distance']) < result[0]['threshold'].unique():\n","              print('\\n')\n","\n","              print('ACCESS GRANTED: You are welcome!')\n","            else:\n","              print('\\n')\n","\n","              print('ACCESS DENIED!')\n","              print('\\n')\n","\n","\n","toc = time.time()\n","print(f'Total time required for code running: {round((toc-tic)/60, 2)} Minutes.')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jJmDUop15-Vs","executionInfo":{"status":"ok","timestamp":1717664907833,"user_tz":-330,"elapsed":60477,"user":{"displayName":"atul kashyap","userId":"02181211827561551789"}},"outputId":"2860e5c7-2d96-48c5-f4ff-cf483b307016","collapsed":true},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ Environment does not support cv2.imshow() or PIL Image.show()\n","\n","\n","\n","WARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n","errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n","\n","Example:\n","    results = model(source=..., stream=True)  # generator of Results objects\n","    for r in results:\n","        boxes = r.boxes  # Boxes object for bbox outputs\n","        masks = r.masks  # Masks object for segment masks outputs\n","        probs = r.probs  # Class probabilities for classification outputs\n","\n","video 1/1 (frame 1/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 34.3ms\n","video 1/1 (frame 2/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 keyboards, 28.4ms\n","video 1/1 (frame 3/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 2 keyboards, 28.4ms\n","video 1/1 (frame 4/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 2 keyboards, 28.4ms\n","video 1/1 (frame 5/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 28.4ms\n","video 1/1 (frame 6/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 34.4ms\n","video 1/1 (frame 7/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 1 keyboard, 38.1ms\n","video 1/1 (frame 8/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 28.3ms\n","video 1/1 (frame 9/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 28.4ms\n","video 1/1 (frame 10/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 28.4ms\n","video 1/1 (frame 11/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 28.4ms\n","video 1/1 (frame 12/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 28.4ms\n","video 1/1 (frame 13/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 1 keyboard, 26.6ms\n","video 1/1 (frame 14/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 26.6ms\n","video 1/1 (frame 15/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 1 keyboard, 26.6ms\n","video 1/1 (frame 16/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 17/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 26.0ms\n","video 1/1 (frame 18/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 19/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 20/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 21/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 22/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 1 keyboard, 26.1ms\n","video 1/1 (frame 23/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 1 keyboard, 26.0ms\n","video 1/1 (frame 24/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 26.1ms\n","video 1/1 (frame 25/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 26.1ms\n","video 1/1 (frame 26/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 1 keyboard, 26.1ms\n","video 1/1 (frame 27/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 26.1ms\n","video 1/1 (frame 28/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 1 keyboard, 26.0ms\n","video 1/1 (frame 29/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 1 keyboard, 26.1ms\n","video 1/1 (frame 30/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 1 keyboard, 26.1ms\n","video 1/1 (frame 31/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 26.1ms\n","video 1/1 (frame 32/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 1 keyboard, 26.1ms\n","video 1/1 (frame 33/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 26.1ms\n","video 1/1 (frame 34/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.4ms\n","video 1/1 (frame 35/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 36/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 37/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 38/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 39/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 27.9ms\n","video 1/1 (frame 40/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 41/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 2 keyboards, 26.0ms\n","video 1/1 (frame 42/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 1 keyboard, 26.1ms\n","video 1/1 (frame 43/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 44/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 27.0ms\n","video 1/1 (frame 45/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 26.1ms\n","video 1/1 (frame 46/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.2ms\n","video 1/1 (frame 47/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 26.6ms\n","video 1/1 (frame 48/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.6ms\n","video 1/1 (frame 49/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 26.6ms\n","video 1/1 (frame 50/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.6ms\n","video 1/1 (frame 51/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.6ms\n","video 1/1 (frame 52/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.6ms\n","video 1/1 (frame 53/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.6ms\n","video 1/1 (frame 54/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.6ms\n","video 1/1 (frame 55/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 56/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.0ms\n","video 1/1 (frame 57/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 58/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 59/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 60/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 61/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 62/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 63/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 64/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.0ms\n","video 1/1 (frame 65/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 66/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 67/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 68/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 69/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 70/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 71/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 26.0ms\n","video 1/1 (frame 72/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.0ms\n","video 1/1 (frame 73/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 74/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 75/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.0ms\n","video 1/1 (frame 76/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 77/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 78/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 79/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 26.6ms\n","video 1/1 (frame 80/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.6ms\n","video 1/1 (frame 81/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.6ms\n","video 1/1 (frame 82/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 83/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 84/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 26.2ms\n","video 1/1 (frame 85/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 86/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 87/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 88/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 89/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 90/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 2 keyboards, 26.1ms\n","video 1/1 (frame 91/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 26.0ms\n","Speed: 4.3ms preprocess, 26.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n","Results saved to \u001b[1mruns/detect/predict21\u001b[0m\n","['keyboard', 'person', 'bottle', 'chair', 'laptop']\n","\n","\n","Moving to eye-blink detection.\n","\n","Total number of blinks detected: 4\n","Moving to face detection.\n","Frame no. 90: 0.970619797706604\n","24-06-06 09:08:13 - Found 9 newly added image(s), 0 removed image(s), 0 replaced image(s).\n"]},{"output_type":"stream","name":"stderr","text":["\rFinding representations:   0%|          | 0/9 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["24-06-06 09:08:14 - vgg_face_weights.h5 will be downloaded...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://github.com/serengil/deepface_models/releases/download/v1.0/vgg_face_weights.h5\n","To: /root/.deepface/weights/vgg_face_weights.h5\n","\n","  0%|          | 0.00/580M [00:00<?, ?B/s]\u001b[A\n","  0%|          | 1.57M/580M [00:00<00:40, 14.3MB/s]\u001b[A\n","  1%|          | 6.29M/580M [00:00<00:17, 32.4MB/s]\u001b[A\n","  4%|▎         | 20.4M/580M [00:00<00:06, 80.6MB/s]\u001b[A\n","  8%|▊         | 45.6M/580M [00:00<00:03, 147MB/s] \u001b[A\n"," 12%|█▏        | 70.8M/580M [00:00<00:02, 184MB/s]\u001b[A\n"," 15%|█▌        | 89.7M/580M [00:00<00:02, 175MB/s]\u001b[A\n"," 19%|█▉        | 111M/580M [00:00<00:02, 182MB/s] \u001b[A\n"," 23%|██▎       | 131M/580M [00:00<00:02, 186MB/s]\u001b[A\n"," 26%|██▋       | 153M/580M [00:00<00:02, 198MB/s]\u001b[A\n"," 31%|███       | 179M/580M [00:01<00:01, 217MB/s]\u001b[A\n"," 35%|███▌      | 206M/580M [00:01<00:01, 229MB/s]\u001b[A\n"," 40%|████      | 233M/580M [00:01<00:01, 243MB/s]\u001b[A\n"," 44%|████▍     | 258M/580M [00:01<00:01, 207MB/s]\u001b[A\n"," 49%|████▉     | 285M/580M [00:01<00:01, 223MB/s]\u001b[A\n"," 54%|█████▍    | 314M/580M [00:01<00:01, 237MB/s]\u001b[A\n"," 59%|█████▉    | 344M/580M [00:01<00:00, 254MB/s]\u001b[A\n"," 64%|██████▍   | 370M/580M [00:02<00:03, 67.0MB/s]\u001b[A\n"," 70%|███████   | 406M/580M [00:02<00:01, 95.2MB/s]\u001b[A\n"," 76%|███████▌  | 441M/580M [00:03<00:01, 126MB/s] \u001b[A\n"," 82%|████████▏ | 476M/580M [00:03<00:00, 158MB/s]\u001b[A\n"," 87%|████████▋ | 505M/580M [00:03<00:00, 178MB/s]\u001b[A\n"," 92%|█████████▏| 534M/580M [00:03<00:00, 185MB/s]\u001b[A\n","100%|██████████| 580M/580M [00:03<00:00, 165MB/s]\n","Finding representations:  22%|██▏       | 2/9 [00:09<00:29,  4.14s/it]"]},{"output_type":"stream","name":"stdout","text":["24-06-06 09:08:23 - 🔴 Exception while extracting faces from /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/Faces/train/AshishGhule/5.jpeg: Face could not be detected in /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/Faces/train/AshishGhule/5.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"]},{"output_type":"stream","name":"stderr","text":["Finding representations:  56%|█████▌    | 5/9 [00:11<00:04,  1.19s/it]"]},{"output_type":"stream","name":"stdout","text":["24-06-06 09:08:25 - 🔴 Exception while extracting faces from /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/Faces/train/AshishGhule/7.jpeg: Face could not be detected in /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/Faces/train/AshishGhule/7.jpeg.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"]},{"output_type":"stream","name":"stderr","text":["Finding representations: 100%|██████████| 9/9 [00:12<00:00,  1.37s/it]\n"]},{"output_type":"stream","name":"stdout","text":["24-06-06 09:08:26 - There are now 10 representations in ds_model_vggface_detector_opencv_aligned_normalization_base_expand_0.pkl\n","24-06-06 09:08:26 - Searching [[[ 95  99  99]\n","  [ 95  99  99]\n","  [ 94  98  98]\n","  ...\n","  [213 206 201]\n","  [213 206 201]\n","  [212 205 205]]\n","\n"," [[ 93  97  97]\n","  [ 93  97  97]\n","  [ 92  96  96]\n","  ...\n","  [213 206 201]\n","  [213 206 201]\n","  [211 204 204]]\n","\n"," [[ 91  95  95]\n","  [ 91  95  95]\n","  [ 91  95  95]\n","  ...\n","  [213 206 201]\n","  [213 206 201]\n","  [213 204 204]]\n","\n"," ...\n","\n"," [[ 51  40  36]\n","  [ 51  40  36]\n","  [ 52  41  37]\n","  ...\n","  [103 108 111]\n","  [103 108 111]\n","  [103 108 111]]\n","\n"," [[ 51  40  36]\n","  [ 51  40  36]\n","  [ 51  40  36]\n","  ...\n","  [103 108 111]\n","  [103 108 111]\n","  [104 109 112]]\n","\n"," [[ 51  40  36]\n","  [ 51  40  36]\n","  [ 51  40  36]\n","  ...\n","  [102 107 110]\n","  [104 109 112]\n","  [103 108 111]]] in 10 length datastore\n","24-06-06 09:08:27 - find function duration 17.797985076904297 seconds\n","\n","\n","ACCESS GRANTED: You are welcome!\n","Total time required for code running: 1.01 Minutes.\n"]}]},{"cell_type":"code","source":["\n","# from deepface import DeepFace\n","\n","# # Path to the database directory\n","# db_path = \"/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/Faces/train/AshishGhule\"\n","\n","\n","# # Perform facial recognition\n","# result = DeepFace.find(cropped_person, db_path, enforce_detection=True)\n","\n","# if min(result[0]['distance']) < result[0]['threshold'].unique():\n","#   print('ACCESS GRANTED: You are welcome!')\n","# else:\n","#   print('ACCESS DENIED!')"],"metadata":{"id":"GXHnaNoP5-b2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["db_path = \"/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/Faces/train/AshishGhule\"\n","\n","suffixes = (\"png\", \"jpg\", \"jpeg\")\n","\n","# Initialize variables\n","is_verified = False\n","threshold_value = None\n","matched_image_path = None\n","my_img_dist = None\n","\n","for i in os.listdir(db_path):\n","  if i.lower().endswith(suffixes):\n","    my_img_path = os.path.join(db_path, i)\n","    vf = DeepFace.verify(cropped_person, my_img_path, model_name = \"Facenet512\", enforce_detection = False)\n","    if vf['distance'] < vf['threshold']:\n","      is_verified = True\n","      thres = vf['threshold']\n","      matched_image_path = my_img_path\n","      my_img_dist = vf['distance']\n","      break\n","    else:\n","      continue\n","\n"],"metadata":{"id":"w7fXdbM_w4en","executionInfo":{"status":"ok","timestamp":1717666100629,"user_tz":-330,"elapsed":1833,"user":{"displayName":"atul kashyap","userId":"02181211827561551789"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["print(is_verified, thres, matched_image_path, my_img_dist)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Clj9LkAY1Kt-","executionInfo":{"status":"ok","timestamp":1717666115241,"user_tz":-330,"elapsed":659,"user":{"displayName":"atul kashyap","userId":"02181211827561551789"}},"outputId":"42cc2fcb-6c3c-410c-f0ce-6b8cb016d789"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["True 0.3 /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/Faces/train/AshishGhule/1.jpeg 0.2848125104617867\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"z4WwvLWT2izW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Version 2"],"metadata":{"id":"V7IwUqq5WZ6c"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import cv2\n","import dlib\n","from imutils import face_utils\n","from scipy.spatial import distance as dist\n","from deepface import DeepFace\n","from ultralytics import YOLO\n","from concurrent.futures import ThreadPoolExecutor\n","import time\n","\n","# Function to calculate eye aspect ratio\n","def eye_aspect_ratio(eye):\n","    A = dist.euclidean(eye[1], eye[5])\n","    B = dist.euclidean(eye[2], eye[4])\n","    C = dist.euclidean(eye[0], eye[3])\n","    ear = (A + B) / (2.0 * C)\n","    return ear\n","\n","# Parameters\n","EYE_AR_THRESH = 0.21\n","EYE_AR_CONSEC_FRAMES = 5\n","objects_of_interest = [\"cell phone\"]   #\"laptop\"\n","\n","# Initialize models\n","model = YOLO('yolov8m.pt')\n","detector = dlib.get_frontal_face_detector()\n","predictor = dlib.shape_predictor('/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/Dependencies/shape_predictor_68_face_landmarks.dat')\n","(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n","(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n","\n","# Path to the video\n","video_path = '/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4'\n","\n","# Start timer\n","tic = time.time()\n","\n","# Open the video file\n","cap = cv2.VideoCapture(video_path)\n","\n","# Get video properties\n","frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","\n","# Define codec and create VideoWriter object\n","output_path = '/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/outputs/output - Ashish.avi'\n","out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'XVID'), 10, (frame_width, frame_height))\n","\n","# Initialize counters\n","COUNTER = 0\n","TOTAL = 0\n","detected_objects = set()\n","\n","# Process frames\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # Run object detection\n","    results = model(frame)\n","\n","    # Process detection results\n","    for result in results:\n","        for detection in result.boxes.data:\n","            class_id = int(detection[5])\n","            class_name = model.names[class_id]\n","            detected_objects.add(class_name)\n","\n","    # Check for unauthorized objects\n","    if any(obj in detected_objects for obj in objects_of_interest):\n","        print(\"UNAUTHORISED ACCESS: Phone/Laptop is detected.\")\n","        cap.release()\n","        out.release()\n","        cv2.destroyAllWindows()\n","        toc = time.time()\n","        print(f'Total time required for code running: {toc-tic}')\n","        exit(1)\n","\n","    # Convert frame to grayscale for eye-blink detection\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","    rects = detector(gray, 0)\n","    for rect in rects:\n","        shape = predictor(gray, rect)\n","        shape = face_utils.shape_to_np(shape)\n","\n","        leftEye = shape[lStart:lEnd]\n","        rightEye = shape[rStart:rEnd]\n","        leftEAR = eye_aspect_ratio(leftEye)\n","        rightEAR = eye_aspect_ratio(rightEye)\n","        ear = (leftEAR + rightEAR) / 2.0\n","\n","        leftEyeHull = cv2.convexHull(leftEye)\n","        rightEyeHull = cv2.convexHull(rightEye)\n","        cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n","        cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n","\n","        if ear < EYE_AR_THRESH:\n","            COUNTER += 1\n","        else:\n","            if COUNTER >= EYE_AR_CONSEC_FRAMES:\n","                TOTAL += 1\n","            COUNTER = 0\n","\n","        cv2.putText(frame, \"Blinks: {}\".format(TOTAL), (10, 30),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n","\n","    # Write the frame to the output video file\n","    out.write(frame)\n","\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","cap.release()\n","out.release()\n","cv2.destroyAllWindows()\n","\n","# Print the final number of blinks\n","print(f\"Total number of blinks detected: {TOTAL}\")\n","\n","if not TOTAL:\n","    print('UNAUTHORISED ACCESS: Spoofing detected')\n","else:\n","    print('Moving to face detection.')\n","\n","    # Initialize variables to store the highest scoring person object and its corresponding frame\n","    highest_score = 0\n","    person_bbox_with_highest_score = None\n","    frame_with_highest_score = None\n","\n","    cap = cv2.VideoCapture(video_path)\n","    frame_idx = 0\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        # Run object detection\n","        results = model(frame)\n","        for result in results:\n","            for detection in result.boxes.data:\n","                x1, y1, x2, y2, conf, cls = detection\n","                if int(cls) == 0 and conf > highest_score:\n","                    highest_score = conf\n","                    person_bbox_with_highest_score = (int(x1), int(y1), int(x2), int(y2))\n","                    frame_with_highest_score = frame.copy()\n","\n","        frame_idx += 1\n","\n","    cap.release()\n","\n","    # If a person object with the highest score is found, crop the corresponding region from the frame\n","    if person_bbox_with_highest_score is not None and frame_with_highest_score is not None:\n","        x1, y1, x2, y2 = person_bbox_with_highest_score\n","        cropped_person = frame_with_highest_score[y1:y2, x1:x2]\n","        print(f'Frame no. {frame_idx}: {highest_score}')\n","        # cv2_imshow(cropped_person)\n","        cv2.waitKey(0)\n","        cv2.destroyAllWindows()\n","\n","        # Path to the database directory\n","        db_path = \"/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/Faces/train/AshishGhule\"\n","\n","        # Perform facial recognition\n","        result = DeepFace.find(cropped_person, db_path, enforce_detection=True)\n","\n","        if min(result[0]['distance']) < result[0]['threshold'].unique():\n","            print('\\n\\nACCESS GRANTED: You are welcome!')\n","        else:\n","            print('\\n\\nACCESS DENIED!')\n","\n","# Stop timer\n","toc = time.time()\n","print(f'Total time required for code running: {round((toc-tic)/60, 2)} Minutes.')\n"],"metadata":{"id":"TPllz8s75-i3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717657439416,"user_tz":-330,"elapsed":441,"user":{"displayName":"atul kashyap","userId":"02181211827561551789"}},"outputId":"9bb232d2-facc-42f6-acd6-cab9829e814e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total time required for code running: 7.23 Minutes.\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"y6RSi4zXf0Wk"}},{"cell_type":"code","source":[],"metadata":{"id":"DGBgkKvdG8S3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BY3mVcevG8WF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Fs5NTASnG8Yq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"SOnLTJFUG8bd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bczIqFTnG8eN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4ERxxXUDG8gQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bUgpnFs3G8iT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2GiYBZTmG8kb"},"execution_count":null,"outputs":[]}]}