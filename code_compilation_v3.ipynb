{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1tPsGURUyw6y6HWDalIc_A63KRZtO55lC","timestamp":1717666146090}],"gpuType":"T4","authorship_tag":"ABX9TyO1AulwgiZ0dvXGRD3ANyIK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Compiling code\n","\n","1.   Object detection in Video\n","2.   Eye blink detection\n","3.   Face recognition\n","\n"],"metadata":{"id":"-VDLaQ_MWWO8"}},{"cell_type":"markdown","source":["Mounting google drive"],"metadata":{"id":"HNR1jRB3cQhD"}},{"cell_type":"code","execution_count":3,"metadata":{"id":"yK3D_B1EWVPX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717745475542,"user_tz":-330,"elapsed":23799,"user":{"displayName":"atul kashyap","userId":"02181211827561551789"}},"outputId":"a669f545-d84b-48f8-c9ce-a5140011862e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","path = '/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled'\n","os.chdir(path)"]},{"cell_type":"markdown","source":["Importing the required libraries"],"metadata":{"id":"anWGrmEfcik2"}},{"cell_type":"code","source":["!pip install ultralytics\n","!pip install deepface\n","# !pip install \"/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/Dependencies/dlib-19.24.1-cp311-cp311-win_amd64.whl\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"F2dXeviacwOk","executionInfo":{"status":"ok","timestamp":1717745496050,"user_tz":-330,"elapsed":17007,"user":{"displayName":"atul kashyap","userId":"02181211827561551789"}},"outputId":"bf83e473-ed9a-4505-cef9-174af44d7e20"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.28)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Requirement already satisfied: ultralytics-thop>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.2.7)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.5.40)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: deepface in /usr/local/lib/python3.10/dist-packages (0.0.91)\n","Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.31.0)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (1.25.2)\n","Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.0.3)\n","Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (5.1.0)\n","Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.66.4)\n","Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (9.4.0)\n","Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from deepface) (4.8.0.76)\n","Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.15.0)\n","Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.15.0)\n","Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from deepface) (2.2.5)\n","Requirement already satisfied: mtcnn>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (0.1.1)\n","Requirement already satisfied: retina-face>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from deepface) (0.0.17)\n","Requirement already satisfied: fire>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (0.6.0)\n","Requirement already satisfied: gunicorn>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from deepface) (22.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (1.16.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->deepface) (2.4.0)\n","Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.0.3)\n","Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (3.1.4)\n","Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n","Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->deepface) (8.1.7)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->deepface) (3.14.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gunicorn>=20.1.0->deepface) (24.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->deepface) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (2024.6.2)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.5.4)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (67.7.2)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (4.12.1)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (1.64.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->deepface) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.43.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=1.1.2->deepface) (2.1.5)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (0.7.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.5)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->deepface) (1.7.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (1.3.1)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=1.9.0->deepface) (3.2.2)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","import cv2\n","from google.colab.patches import cv2_imshow\n","from ultralytics import YOLO\n","\n","import dlib\n","from imutils import face_utils\n","from scipy.spatial import distance as dist\n","\n","from deepface import DeepFace\n","\n","import time\n","\n","# Start timer\n","tic = time.time()\n","\n","# Load the pre-trained model for YOLOv8\n","model = YOLO('yolov8m.pt')\n","\n","# Path to the video\n","video_path = '/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4'\n","\n","# Run the video through the model\n","results = model(source=video_path, show=True, conf=0.4, save=True)\n","\n","tc = time.time()\n","print(tc-tic)\n","\n","# Initialize an empty set to store unique object names\n","detected_objects = set()\n","\n","# Process the results\n","for result in results:\n","    for detection in result.boxes.data:\n","        class_id = int(detection[5])\n","        class_name = model.names[class_id]\n","        detected_objects.add(class_name)\n","\n","# Convert the set to a list to get the final list of detected objects\n","objects_list = list(detected_objects)\n","print(objects_list)\n","print('\\n')\n","\n","# Check for unauthorized objects\n","objects_of_interest = [\"cell phone\"]  # \"laptop\"\n","if any(obj in objects_list for obj in objects_of_interest):\n","    print(\"UNAUTHORISED ACCESS: Phone/Laptop is detected.\")\n","else:\n","    print('Moving to eye-blink detection.\\n')\n","\n","    def eye_aspect_ratio(eye):\n","        A = dist.euclidean(eye[1], eye[5])\n","        B = dist.euclidean(eye[2], eye[4])\n","        C = dist.euclidean(eye[0], eye[3])\n","        ear = (A + B) / (2.0 * C)\n","        return ear\n","\n","    EYE_AR_THRESH = 0.21\n","    EYE_AR_CONSEC_FRAMES = 5\n","\n","    # Initialize counters\n","    COUNTER = 0\n","    TOTAL = 0\n","\n","    # Initialize dlib's face detector and create the facial landmark predictor\n","    detector = dlib.get_frontal_face_detector()\n","    predictor = dlib.shape_predictor('/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/Dependencies/shape_predictor_68_face_landmarks.dat')\n","\n","    (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n","    (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n","\n","    # Open the video file again for eye blink detection\n","    cap = cv2.VideoCapture(video_path)\n","\n","    # Get the width and height of the frames in the video\n","    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","    # Define the codec and create VideoWriter object\n","    output_path = '/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/outputs/output - Ashish.avi'\n","    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'XVID'), 10, (frame_width, frame_height))\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","        rects = detector(gray, 0)\n","\n","        for rect in rects:\n","            shape = predictor(gray, rect)\n","            shape = face_utils.shape_to_np(shape)\n","\n","            leftEye = shape[lStart:lEnd]\n","            rightEye = shape[rStart:rEnd]\n","            leftEAR = eye_aspect_ratio(leftEye)\n","            rightEAR = eye_aspect_ratio(rightEye)\n","\n","            ear = (leftEAR + rightEAR) / 2.0\n","\n","            leftEyeHull = cv2.convexHull(leftEye)\n","            rightEyeHull = cv2.convexHull(rightEye)\n","            cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n","            cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n","\n","            if ear < EYE_AR_THRESH:\n","                COUNTER += 1\n","            else:\n","                if COUNTER >= EYE_AR_CONSEC_FRAMES:\n","                    TOTAL += 1\n","                COUNTER = 0\n","\n","            cv2.putText(frame, \"Blinks: {}\".format(TOTAL), (10, 30),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 3, (0, 0, 255), 2)\n","\n","        # Write the frame to the output video file\n","        out.write(frame)\n","\n","        if cv2.waitKey(1) & 0xFF == ord('q'):\n","            break\n","\n","    cap.release()\n","    out.release()\n","    cv2.destroyAllWindows()\n","\n","    # Print the final number of blinks\n","    print(f\"Total number of blinks detected: {TOTAL}\")\n","\n","    if not TOTAL:\n","        print('UNAUTHORISED ACCESS: Spoofing detected')\n","    else:\n","        print('Moving to face detection.')\n","\n","        # Initialize variables to store the highest scoring person object and its corresponding frame\n","        highest_score = 0\n","        person_bbox_with_highest_score = None\n","        frame_with_highest_score = None\n","\n","        # Open the video file again for face detection\n","        cap = cv2.VideoCapture(video_path)\n","\n","        # Iterate over the detected frames\n","        for frame_idx, frame_results in enumerate(results):\n","            for detection in frame_results.boxes.data:\n","                x1, y1, x2, y2, conf, cls = detection\n","\n","                # Check if the detected object is a person (assuming class '0' corresponds to 'person')\n","                if int(cls) == 0 and conf > highest_score:\n","                    highest_score = conf\n","                    person_bbox_with_highest_score = (int(x1), int(y1), int(x2), int(y2))\n","\n","                    # Set the video frame to the current frame index\n","                    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n","                    ret, frame_with_highest_score = cap.read()\n","\n","        cap.release()\n","\n","        # If a person object with the highest score is found, crop the corresponding region from the frame\n","        if person_bbox_with_highest_score is not None and frame_with_highest_score is not None:\n","            x1, y1, x2, y2 = person_bbox_with_highest_score\n","            cropped_person = frame_with_highest_score[y1:y2, x1:x2]\n","            # Display or save the cropped person image\n","            print(f'Frame no. {frame_idx}: {highest_score}')\n","            # cv2_imshow(cropped_person)\n","            cv2.waitKey(0)\n","            cv2.destroyAllWindows()\n","\n","\n","            # --------- FACE RECOGNITION ---------\n","\n","            # Path to the database directory\n","            # db_path = \"/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/Faces/train/AshishGhule\"\n","            db_path = \"/content/drive/MyDrive/Colab Notebooks/ND Face Recognition/Faces/train/AkshayFadnavis\"\n","            suffixes = (\"png\", \"jpg\", \"jpeg\")\n","\n","            # Initialize variables\n","            is_verified = False\n","            threshold_value = None\n","            matched_image_path = None\n","            my_img_dist = None\n","\n","            for i in os.listdir(db_path):\n","              if i.lower().endswith(suffixes):\n","                my_img_path = os.path.join(db_path, i)\n","                try:\n","                  vf = DeepFace.verify(cropped_person, my_img_path, model_name = \"Facenet512\", enforce_detection = False)\n","                  if vf['distance'] < vf['threshold']:\n","                    is_verified = True\n","                    thres = vf['threshold']\n","                    matched_image_path = my_img_path\n","                    my_img_dist = vf['distance']\n","                    break\n","                except Exception as e:\n","                  print(f\"Error processing {my_img_path}: {e}\")\n","                  continue\n","\n","            if is_verified:\n","              print(\"ACCESS GRANTED: Face verified!\")\n","            else:\n","              print(\"ACCESS DENIED: Face not verified!\")\n","\n","toc = time.time()\n","print(f'Total time required for code running: {round((toc-tic)/60, 2)} Minutes.')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jJmDUop15-Vs","executionInfo":{"status":"ok","timestamp":1717745700291,"user_tz":-330,"elapsed":204247,"user":{"displayName":"atul kashyap","userId":"02181211827561551789"}},"outputId":"45d45e7e-e653-4a4f-e73a-ab84452adeef"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ Environment does not support cv2.imshow() or PIL Image.show()\n","\n","\n","\n","WARNING ⚠️ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n","errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n","\n","Example:\n","    results = model(source=..., stream=True)  # generator of Results objects\n","    for r in results:\n","        boxes = r.boxes  # Boxes object for bbox outputs\n","        masks = r.masks  # Masks object for segment masks outputs\n","        probs = r.probs  # Class probabilities for classification outputs\n","\n","video 1/1 (frame 1/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1369.2ms\n","video 1/1 (frame 2/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 keyboards, 3309.8ms\n","video 1/1 (frame 3/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 2 keyboards, 3875.9ms\n","video 1/1 (frame 4/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 2 keyboards, 2310.8ms\n","video 1/1 (frame 5/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 1917.0ms\n","video 1/1 (frame 6/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 2133.9ms\n","video 1/1 (frame 7/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 1 keyboard, 1090.1ms\n","video 1/1 (frame 8/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1095.6ms\n","video 1/1 (frame 9/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 1119.2ms\n","video 1/1 (frame 10/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 1688.5ms\n","video 1/1 (frame 11/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 1669.2ms\n","video 1/1 (frame 12/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1625.5ms\n","video 1/1 (frame 13/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 1 keyboard, 1068.2ms\n","video 1/1 (frame 14/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 1084.0ms\n","video 1/1 (frame 15/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 1 keyboard, 1041.1ms\n","video 1/1 (frame 16/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 1072.7ms\n","video 1/1 (frame 17/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 1063.1ms\n","video 1/1 (frame 18/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 1072.1ms\n","video 1/1 (frame 19/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1061.6ms\n","video 1/1 (frame 20/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1073.4ms\n","video 1/1 (frame 21/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 1214.0ms\n","video 1/1 (frame 22/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 1 keyboard, 1698.0ms\n","video 1/1 (frame 23/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 1 keyboard, 1681.7ms\n","video 1/1 (frame 24/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 1470.0ms\n","video 1/1 (frame 25/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 1064.0ms\n","video 1/1 (frame 26/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 1 keyboard, 1065.1ms\n","video 1/1 (frame 27/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 1050.6ms\n","video 1/1 (frame 28/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 1 keyboard, 1066.6ms\n","video 1/1 (frame 29/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 1 keyboard, 1077.5ms\n","video 1/1 (frame 30/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 1 keyboard, 1092.8ms\n","video 1/1 (frame 31/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 1054.7ms\n","video 1/1 (frame 32/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 1 keyboard, 1053.0ms\n","video 1/1 (frame 33/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 1382.9ms\n","video 1/1 (frame 34/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1715.7ms\n","video 1/1 (frame 35/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1811.4ms\n","video 1/1 (frame 36/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 2 keyboards, 1224.6ms\n","video 1/1 (frame 37/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 2 keyboards, 1052.7ms\n","video 1/1 (frame 38/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1065.6ms\n","video 1/1 (frame 39/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1072.5ms\n","video 1/1 (frame 40/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1053.2ms\n","video 1/1 (frame 41/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 2 keyboards, 1091.3ms\n","video 1/1 (frame 42/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 1 keyboard, 1069.1ms\n","video 1/1 (frame 43/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1073.7ms\n","video 1/1 (frame 44/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1773.2ms\n","video 1/1 (frame 45/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 1704.6ms\n","video 1/1 (frame 46/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1699.9ms\n","video 1/1 (frame 47/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 1551.1ms\n","video 1/1 (frame 48/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1061.3ms\n","video 1/1 (frame 49/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 1 keyboard, 1086.1ms\n","video 1/1 (frame 50/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1062.6ms\n","video 1/1 (frame 51/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1051.0ms\n","video 1/1 (frame 52/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1057.6ms\n","video 1/1 (frame 53/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1066.0ms\n","video 1/1 (frame 54/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1065.2ms\n","video 1/1 (frame 55/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1055.4ms\n","video 1/1 (frame 56/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1298.9ms\n","video 1/1 (frame 57/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 2625.3ms\n","video 1/1 (frame 58/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 2145.6ms\n","video 1/1 (frame 59/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1057.1ms\n","video 1/1 (frame 60/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1074.9ms\n","video 1/1 (frame 61/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 1073.6ms\n","video 1/1 (frame 62/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1053.0ms\n","video 1/1 (frame 63/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1089.7ms\n","video 1/1 (frame 64/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1045.8ms\n","video 1/1 (frame 65/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1064.0ms\n","video 1/1 (frame 66/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1077.9ms\n","video 1/1 (frame 67/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1075.0ms\n","video 1/1 (frame 68/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 1687.8ms\n","video 1/1 (frame 69/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1701.2ms\n","video 1/1 (frame 70/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1650.0ms\n","video 1/1 (frame 71/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 1054.7ms\n","video 1/1 (frame 72/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1073.1ms\n","video 1/1 (frame 73/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 1083.0ms\n","video 1/1 (frame 74/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 1064.4ms\n","video 1/1 (frame 75/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1058.2ms\n","video 1/1 (frame 76/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 1060.5ms\n","video 1/1 (frame 77/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1087.2ms\n","video 1/1 (frame 78/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 1054.2ms\n","video 1/1 (frame 79/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 1168.3ms\n","video 1/1 (frame 80/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1710.9ms\n","video 1/1 (frame 81/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1735.4ms\n","video 1/1 (frame 82/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 1476.8ms\n","video 1/1 (frame 83/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 1077.8ms\n","video 1/1 (frame 84/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 2 chairs, 1 laptop, 2 keyboards, 1077.0ms\n","video 1/1 (frame 85/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1069.4ms\n","video 1/1 (frame 86/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1079.8ms\n","video 1/1 (frame 87/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 2 keyboards, 1108.2ms\n","video 1/1 (frame 88/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 2 keyboards, 1084.5ms\n","video 1/1 (frame 89/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 2 keyboards, 1079.6ms\n","video 1/1 (frame 90/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 laptop, 2 keyboards, 1092.9ms\n","video 1/1 (frame 91/91) /content/drive/MyDrive/Colab Notebooks/ND Face Recognition/compiled/inputs/Ashish.mp4: 640x480 1 person, 1 bottle, 1 chair, 1 laptop, 2 keyboards, 1429.9ms\n","Speed: 6.1ms preprocess, 1325.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n","Results saved to \u001b[1mruns/detect/predict31\u001b[0m\n","133.5104489326477\n","['person', 'keyboard', 'chair', 'laptop', 'bottle']\n","\n","\n","Moving to eye-blink detection.\n","\n","Total number of blinks detected: 4\n","Moving to face detection.\n","Frame no. 90: 0.970619797706604\n","24-06-07 07:34:23 - facenet512_weights.h5 will be downloaded...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://github.com/serengil/deepface_models/releases/download/v1.0/facenet512_weights.h5\n","To: /root/.deepface/weights/facenet512_weights.h5\n","100%|██████████| 95.0M/95.0M [00:00<00:00, 134MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["ACCESS DENIED: Face not verified!\n","Total time required for code running: 3.42 Minutes.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"r_gvBngUbt0p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aVJuS_Rrbt3B"},"execution_count":null,"outputs":[]}]}